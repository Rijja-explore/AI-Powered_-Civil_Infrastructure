{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760a68dc",
   "metadata": {},
   "source": [
    "## Section 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6af1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu, f_oneway, chi2_contingency\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Utilities\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import analytics pipeline\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from analytics_pipeline import (\n",
    "    load_images_from_dataset,\n",
    "    preprocess_image,\n",
    "    extract_crack_features,\n",
    "    extract_vegetation_features,\n",
    "    compute_risk_score,\n",
    "    build_dataframes,\n",
    "    run_statistical_tests,\n",
    "    export_dataset_analytics,\n",
    "    export_image_insights\n",
    ")\n",
    "\n",
    "print('✅ All libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857897aa",
   "metadata": {},
   "source": [
    "## Section 2: Load and Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5727c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset paths\n",
    "base_path = Path('.')\n",
    "crack_dir = base_path / 'Dataset' / 'crack_preprocess'\n",
    "vegetation_dir = base_path / 'Dataset' / 'vegetation_preprocess'\n",
    "\n",
    "print(f'Crack dataset path: {crack_dir}')\n",
    "print(f'Vegetation dataset path: {vegetation_dir}')\n",
    "\n",
    "# Load all images\n",
    "print('\\nLoading datasets...')\n",
    "crack_data, vegetation_data = load_images_from_dataset(\n",
    "    crack_dir=str(crack_dir),\n",
    "    vegetation_dir=str(vegetation_dir),\n",
    "    target_size=(640, 640)\n",
    ")\n",
    "\n",
    "print(f'\\n✅ Crack images: {len(crack_data[\"images\"])}')\n",
    "print(f'✅ Vegetation images: {len(vegetation_data[\"images\"])}')\n",
    "\n",
    "# Display sample images\n",
    "if len(crack_data['images']) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].imshow(crack_data['images'][0])\n",
    "    axes[0].set_title(f'Sample Crack: {crack_data[\"filenames\"][0]}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    if len(vegetation_data['images']) > 0:\n",
    "        axes[1].imshow(vegetation_data['images'][0])\n",
    "        axes[1].set_title(f'Sample Vegetation: {vegetation_data[\"filenames\"][0]}')\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e2839",
   "metadata": {},
   "source": [
    "## Section 3: Extract Features from All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract crack features\n",
    "print('Extracting crack features...')\n",
    "crack_features_list = []\n",
    "crack_risk_scores = []\n",
    "\n",
    "for i, img in enumerate(crack_data['images']):\n",
    "    try:\n",
    "        features = extract_crack_features(img)\n",
    "        risk_score = compute_risk_score(features, feature_type='crack')\n",
    "        crack_features_list.append(features)\n",
    "        crack_risk_scores.append(risk_score)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing crack image {i}: {e}')\n",
    "        # Add default features\n",
    "        crack_features_list.append({f: 0.0 for f in ['crack_pixel_ratio', 'edge_density', 'skeleton_length_proxy', 'glcm_entropy', 'brightness', 'color_mean_r', 'color_mean_g', 'color_mean_b', 'roughness']})\n",
    "        crack_risk_scores.append(0.0)\n",
    "\n",
    "print(f'✅ Extracted {len(crack_features_list)} crack feature sets')\n",
    "\n",
    "# Extract vegetation features\n",
    "print('\\nExtracting vegetation features...')\n",
    "vegetation_features_list = []\n",
    "vegetation_risk_scores = []\n",
    "\n",
    "for i, img in enumerate(vegetation_data['images']):\n",
    "    try:\n",
    "        features = extract_vegetation_features(img)\n",
    "        risk_score = compute_risk_score(features, feature_type='vegetation')\n",
    "        vegetation_features_list.append(features)\n",
    "        vegetation_risk_scores.append(risk_score)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing vegetation image {i}: {e}')\n",
    "        vegetation_features_list.append({f: 0.0 for f in ['vegetation_coverage', 'green_index_mean', 'glcm_entropy', 'brightness', 'color_mean_r', 'color_mean_g', 'color_mean_b', 'roughness', 'saturation_mean']})\n",
    "        vegetation_risk_scores.append(0.0)\n",
    "\n",
    "print(f'✅ Extracted {len(vegetation_features_list)} vegetation feature sets')\n",
    "\n",
    "# Show sample features\n",
    "print('\\nSample Crack Features:')\n",
    "print(crack_features_list[0] if crack_features_list else 'No crack images')\n",
    "\n",
    "print('\\nSample Vegetation Features:')\n",
    "print(vegetation_features_list[0] if vegetation_features_list else 'No vegetation images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeff378",
   "metadata": {},
   "source": [
    "## Section 4: Build Analytical DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02779898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DataFrames\n",
    "print('Building DataFrames...')\n",
    "df_crack, df_vegetation = build_dataframes(\n",
    "    crack_data=crack_data,\n",
    "    vegetation_data=vegetation_data,\n",
    "    crack_features_list=crack_features_list,\n",
    "    vegetation_features_list=vegetation_features_list,\n",
    "    crack_risk_scores=crack_risk_scores,\n",
    "    vegetation_risk_scores=vegetation_risk_scores\n",
    ")\n",
    "\n",
    "print(f'✅ Crack DataFrame: {df_crack.shape}')\n",
    "print(f'✅ Vegetation DataFrame: {df_vegetation.shape}')\n",
    "\n",
    "print('\\nCrack DataFrame Info:')\n",
    "print(df_crack.head())\n",
    "\n",
    "print('\\nCrack Statistics:')\n",
    "print(df_crack.describe())\n",
    "\n",
    "print('\\nVegetation DataFrame Info:')\n",
    "print(df_vegetation.head())\n",
    "\n",
    "print('\\nVegetation Statistics:')\n",
    "print(df_vegetation.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dd040b",
   "metadata": {},
   "source": [
    "## Section 5: Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization dashboard\n",
    "print('Creating visualization dashboard...')\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Row 1: Crack features\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "if 'crack_pixel_ratio' in df_crack.columns:\n",
    "    ax1.hist(df_crack['crack_pixel_ratio'], bins=20, color='crimson', alpha=0.7, edgecolor='black')\n",
    "    ax1.set_title('Crack Pixel Ratio Distribution')\n",
    "    ax1.set_xlabel('Ratio')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "if 'edge_density' in df_crack.columns:\n",
    "    ax2.hist(df_crack['edge_density'], bins=20, color='orange', alpha=0.7, edgecolor='black')\n",
    "    ax2.set_title('Edge Density (Canny) Distribution')\n",
    "    ax2.set_xlabel('Density')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "if 'severity' in df_crack.columns:\n",
    "    severity_counts = df_crack['severity'].value_counts()\n",
    "    ax3.bar(severity_counts.index, severity_counts.values, color='steelblue', edgecolor='black')\n",
    "    ax3.set_title('Crack Severity Distribution')\n",
    "    ax3.set_xlabel('Severity')\n",
    "    ax3.set_ylabel('Count')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Row 2: Crack analysis\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "if 'crack_pixel_ratio' in df_crack.columns and 'edge_density' in df_crack.columns:\n",
    "    scatter = ax4.scatter(df_crack['crack_pixel_ratio'], df_crack['edge_density'], \n",
    "                          c=df_crack['risk_score'], cmap='RdYlGn_r', s=50, alpha=0.6)\n",
    "    ax4.set_title('Crack Density vs Edge Density')\n",
    "    ax4.set_xlabel('Crack Pixel Ratio')\n",
    "    ax4.set_ylabel('Edge Density')\n",
    "    plt.colorbar(scatter, ax=ax4, label='Risk Score')\n",
    "\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "if 'risk_score' in df_crack.columns:\n",
    "    ax5.hist(df_crack['risk_score'], bins=20, color='darkred', alpha=0.7, edgecolor='black')\n",
    "    ax5.set_title('Crack Risk Score Distribution')\n",
    "    ax5.set_xlabel('Risk Score')\n",
    "    ax5.set_ylabel('Frequency')\n",
    "\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "numeric_crack_cols = df_crack.select_dtypes(include=[np.number]).columns[:8]\n",
    "if len(numeric_crack_cols) > 1:\n",
    "    corr_matrix = df_crack[numeric_crack_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, ax=ax6, cbar=True)\n",
    "    ax6.set_title('Crack Features Correlation')\n",
    "    ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Row 3: Vegetation features\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "if 'vegetation_coverage' in df_vegetation.columns:\n",
    "    ax7.hist(df_vegetation['vegetation_coverage'], bins=20, color='green', alpha=0.7, edgecolor='black')\n",
    "    ax7.set_title('Vegetation Coverage Distribution')\n",
    "    ax7.set_xlabel('Coverage %')\n",
    "    ax7.set_ylabel('Frequency')\n",
    "\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "if 'type' in df_vegetation.columns:\n",
    "    type_counts = df_vegetation['type'].value_counts()\n",
    "    ax8.bar(type_counts.index, type_counts.values, color='forestgreen', edgecolor='black')\n",
    "    ax8.set_title('Vegetation Type Distribution')\n",
    "    ax8.set_xlabel('Type')\n",
    "    ax8.set_ylabel('Count')\n",
    "    ax8.tick_params(axis='x', rotation=45)\n",
    "\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "if 'vegetation_coverage' in df_vegetation.columns and 'green_index_mean' in df_vegetation.columns:\n",
    "    scatter = ax9.scatter(df_vegetation['vegetation_coverage'], df_vegetation['green_index_mean'],\n",
    "                          c=df_vegetation['risk_score'], cmap='RdYlGn_r', s=50, alpha=0.6)\n",
    "    ax9.set_title('Coverage vs Green Index')\n",
    "    ax9.set_xlabel('Coverage')\n",
    "    ax9.set_ylabel('Green Index')\n",
    "    plt.colorbar(scatter, ax=ax9, label='Risk Score')\n",
    "\n",
    "# Row 4: Overall metrics\n",
    "ax10 = fig.add_subplot(gs[3, 0])\n",
    "if 'risk_score' in df_vegetation.columns:\n",
    "    ax10.hist(df_vegetation['risk_score'], bins=20, color='darkgreen', alpha=0.7, edgecolor='black')\n",
    "    ax10.set_title('Vegetation Risk Score Distribution')\n",
    "    ax10.set_xlabel('Risk Score')\n",
    "    ax10.set_ylabel('Frequency')\n",
    "\n",
    "ax11 = fig.add_subplot(gs[3, 1])\n",
    "numeric_veg_cols = df_vegetation.select_dtypes(include=[np.number]).columns[:8]\n",
    "if len(numeric_veg_cols) > 1:\n",
    "    corr_matrix = df_vegetation[numeric_veg_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, ax=ax11, cbar=True)\n",
    "    ax11.set_title('Vegetation Features Correlation')\n",
    "    ax11.tick_params(axis='x', rotation=45)\n",
    "\n",
    "ax12 = fig.add_subplot(gs[3, 2])\n",
    "if 'split' in df_crack.columns:\n",
    "    combined_risk = pd.concat([\n",
    "        df_crack[['split', 'risk_score']].assign(type='Crack'),\n",
    "        df_vegetation[['split', 'risk_score']].assign(type='Vegetation')\n",
    "    ])\n",
    "    split_order = ['train', 'test', 'valid']\n",
    "    splits_present = [s for s in split_order if s in combined_risk['split'].values]\n",
    "    data_by_split = [combined_risk[combined_risk['split'] == s]['risk_score'].values for s in splits_present]\n",
    "    ax12.boxplot(data_by_split, labels=splits_present)\n",
    "    ax12.set_title('Risk Score by Dataset Split')\n",
    "    ax12.set_ylabel('Risk Score')\n",
    "\n",
    "plt.suptitle('Infrastructure Health Analytics Dashboard', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.savefig('analytics_dashboard.png', dpi=150, bbox_inches='tight')\n",
    "print('✅ Dashboard saved as analytics_dashboard.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c14729",
   "metadata": {},
   "source": [
    "## Section 6: Run Statistical Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run statistical tests\n",
    "print('Running statistical hypothesis tests...\\n')\n",
    "statistical_tests = run_statistical_tests(df_crack, df_vegetation)\n",
    "\n",
    "# Display results\n",
    "for i, test in enumerate(statistical_tests, 1):\n",
    "    print(f\"Test {i}: {test['test_name']}\")\n",
    "    print(f\"  Description: {test.get('description', 'N/A')}\")\n",
    "    print(f\"  P-value: {test['p_value']:.6f}\")\n",
    "    print(f\"  Significant (α=0.05): {test['significant']}\")\n",
    "    print(f\"  Interpretation: {test['interpretation']}\")\n",
    "    if 'r_squared' in test:\n",
    "        print(f\"  R²: {test['r_squared']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee3335",
   "metadata": {},
   "source": [
    "## Section 7: Export Dataset Analytics JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics\n",
    "from analytics_pipeline.statistics import compute_dataset_statistics\n",
    "\n",
    "print('Computing dataset statistics...')\n",
    "crack_stats = compute_dataset_statistics(df_crack, prefix='crack_')\n",
    "vegetation_stats = compute_dataset_statistics(df_vegetation, prefix='vegetation_')\n",
    "\n",
    "# Export JSON\n",
    "print('\\nExporting dataset analytics JSON...')\n",
    "json_path = export_dataset_analytics(\n",
    "    df_crack=df_crack,\n",
    "    df_vegetation=df_vegetation,\n",
    "    statistical_tests=statistical_tests,\n",
    "    crack_stats=crack_stats,\n",
    "    vegetation_stats=vegetation_stats,\n",
    "    output_path='dataset_analytics.json'\n",
    ")\n",
    "\n",
    "# Show sample of exported data\n",
    "with open('dataset_analytics.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    print('\\nExported JSON structure:')\n",
    "    print(json.dumps({k: type(v).__name__ for k, v in data.items()}, indent=2))\n",
    "    print(f\"\\nTotal size: {len(json.dumps(data)) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b363a",
   "metadata": {},
   "source": [
    "## Section 8: ImageInsightsAnalyzer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c6d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageInsightsAnalyzer:\n",
    "    \"\"\"Analyzes a single image relative to dataset statistics.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_analytics_path='dataset_analytics.json'):\n",
    "        \"\"\"Initialize with dataset statistics.\"\"\"\n",
    "        with open(dataset_analytics_path, 'r') as f:\n",
    "            self.dataset = json.load(f)\n",
    "    \n",
    "    def analyze_image(self, image_metrics):\n",
    "        \"\"\"\n",
    "        Analyze a single image.\n",
    "        \n",
    "        Args:\n",
    "            image_metrics: Dict with keys:\n",
    "                - crack_risk_score\n",
    "                - vegetation_risk_score\n",
    "                - moisture_intensity\n",
    "                - stress_index\n",
    "                - etc.\n",
    "        \n",
    "        Returns:\n",
    "            Dict with analysis results\n",
    "        \"\"\"\n",
    "        from analytics_pipeline.export_json import (\n",
    "            compute_health_score,\n",
    "            get_risk_level,\n",
    "            generate_insights,\n",
    "            compute_overlap_analysis,\n",
    "            compute_contribution_breakdown,\n",
    "            generate_radar_chart_data,\n",
    "            generate_summary\n",
    "        )\n",
    "        \n",
    "        # Extract dataset stats\n",
    "        crack_stats = self.dataset['crack_analysis']['metrics']\n",
    "        vegetation_stats = self.dataset['vegetation_analysis']['metrics']\n",
    "        \n",
    "        all_stats = {**crack_stats, **vegetation_stats}\n",
    "        \n",
    "        # Compute health and risk\n",
    "        health_score = compute_health_score(image_metrics)\n",
    "        risk_level = get_risk_level(health_score)\n",
    "        \n",
    "        # Generate insights\n",
    "        insights = self.generate_detailed_insights(image_metrics, all_stats)\n",
    "        \n",
    "        # Overlap and contribution\n",
    "        overlap = compute_overlap_analysis(image_metrics)\n",
    "        contribution = compute_contribution_breakdown(image_metrics)\n",
    "        \n",
    "        # Radar chart\n",
    "        radar_data = generate_radar_chart_data(image_metrics, all_stats)\n",
    "        \n",
    "        return {\n",
    "            'summary': generate_summary(health_score, risk_level, image_metrics),\n",
    "            'health_score': int(health_score),\n",
    "            'risk_level': risk_level,\n",
    "            'radar_chart_data': radar_data,\n",
    "            'overlap_analysis': overlap,\n",
    "            'contribution_breakdown': contribution,\n",
    "            'insights': insights\n",
    "        }\n",
    "    \n",
    "    def generate_detailed_insights(self, image_metrics, dataset_stats):\n",
    "        \"\"\"Generate actionable insights.\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        # Crack insights\n",
    "        if image_metrics.get('crack_risk_score', 0) > 0.5:\n",
    "            insights.append({\n",
    "                'type': 'warning',\n",
    "                'message': 'High crack density detected. Surface integrity at risk. Schedule inspection.'\n",
    "            })\n",
    "        \n",
    "        # Vegetation insights\n",
    "        if image_metrics.get('vegetation_risk_score', 0) > 0.5:\n",
    "            insights.append({\n",
    "                'type': 'warning',\n",
    "                'message': 'Significant biological growth detected. Accelerates moisture retention and degradation.'\n",
    "            })\n",
    "        \n",
    "        # Moisture insights\n",
    "        if image_metrics.get('moisture_intensity', 0) > 0.6:\n",
    "            insights.append({\n",
    "                'type': 'warning',\n",
    "                'message': 'High moisture detected in multiple zones. Risk of accelerated corrosion.'\n",
    "            })\n",
    "        \n",
    "        # Combined risk\n",
    "        combined_risk = (image_metrics.get('crack_risk_score', 0) + \n",
    "                        image_metrics.get('vegetation_risk_score', 0) + \n",
    "                        image_metrics.get('moisture_intensity', 0)) / 3\n",
    "        \n",
    "        if combined_risk > 0.6:\n",
    "            insights.append({\n",
    "                'type': 'warning',\n",
    "                'message': 'Multiple degradation factors detected. Recommend immediate detailed assessment.'\n",
    "            })\n",
    "        elif len(insights) == 0:\n",
    "            insights.append({\n",
    "                'type': 'ok',\n",
    "                'message': 'Surface condition is stable. Continue routine monitoring.'\n",
    "            })\n",
    "        \n",
    "        return insights[:5]  # Limit to top 5\n",
    "\n",
    "print('✅ ImageInsightsAnalyzer class defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622130b",
   "metadata": {},
   "source": [
    "## Section 9: Example Per-Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example image metrics (simulated)\n",
    "example_image_metrics = {\n",
    "    'crack_risk_score': 0.62,\n",
    "    'vegetation_risk_score': 0.35,\n",
    "    'moisture_intensity': 0.58,\n",
    "    'stress_index': 0.42,\n",
    "    'thermal_hotspot_score': 0.21,\n",
    "    'material_durability': 0.68\n",
    "}\n",
    "\n",
    "# Analyze\n",
    "print('Analyzing example image...\\n')\n",
    "analyzer = ImageInsightsAnalyzer('dataset_analytics.json')\n",
    "image_analysis = analyzer.analyze_image(example_image_metrics)\n",
    "\n",
    "# Display results\n",
    "print('Image Analysis Results:')\n",
    "print(f\"  Health Score: {image_analysis['health_score']}/100\")\n",
    "print(f\"  Risk Level: {image_analysis['risk_level']}\")\n",
    "print(f\"  Summary: {image_analysis['summary']}\")\n",
    "print(f\"\\n  Insights:\")\n",
    "for insight in image_analysis['insights']:\n",
    "    print(f\"    [{insight['type'].upper()}] {insight['message']}\")\n",
    "\n",
    "print(f\"\\n  Overlap Analysis:\")\n",
    "for key, value in image_analysis['overlap_analysis'].items():\n",
    "    print(f\"    {key}: {value:.1f}%\")\n",
    "\n",
    "print(f\"\\n  Feature Contribution:\")\n",
    "for contrib in image_analysis['contribution_breakdown']:\n",
    "    print(f\"    {contrib['feature']}: {contrib['contribution_to_risk']:.1f} (weight: {contrib['weight']:.2f})\")\n",
    "\n",
    "# Export example to JSON\n",
    "with open('example_image_insights.json', 'w') as f:\n",
    "    json.dump(image_analysis, f, indent=2)\n",
    "print('\\n✅ Example image insights exported to example_image_insights.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82221440",
   "metadata": {},
   "source": [
    "## Section 10: React Architecture & Data Persistence Guide\n",
    "\n",
    "### Problem: Data Disappears on Tab Switch\n",
    "\n",
    "When users switch between tabs (e.g., ImageAnalysis → ImageInsights → ImageAnalysis), the analysis results disappear.\n",
    "\n",
    "**Root Cause:** Component unmount. When you leave a tab, the component is destroyed, and local state is lost.\n",
    "\n",
    "### Solution: Shared State Pattern (\"Lift State Up\")\n",
    "\n",
    "Move the `lastAnalysis` state to the parent component (MainDashboard) so it persists across tab switches.\n",
    "\n",
    "#### Implementation:\n",
    "\n",
    "**1. Create AnalysisContext (new file: `frontend/src/contexts/AnalysisContext.js`):**\n",
    "\n",
    "```jsx\n",
    "import React, { createContext, useState } from 'react';\n",
    "\n",
    "export const AnalysisContext = createContext();\n",
    "\n",
    "export const AnalysisProvider = ({ children }) => {\n",
    "  const [lastAnalysis, setLastAnalysis] = useState(null);\n",
    "  \n",
    "  return (\n",
    "    <AnalysisContext.Provider value={{ lastAnalysis, setLastAnalysis }}>\n",
    "      {children}\n",
    "    </AnalysisContext.Provider>\n",
    "  );\n",
    "};\n",
    "```\n",
    "\n",
    "**2. Update MainDashboard.jsx:**\n",
    "\n",
    "```jsx\n",
    "import { AnalysisProvider } from './contexts/AnalysisContext';\n",
    "import ImageAnalysis from './pages/ImageAnalysis';\n",
    "import ImageInsights from './pages/ImageInsights';\n",
    "\n",
    "const MainDashboard = () => {\n",
    "  return (\n",
    "    <AnalysisProvider>\n",
    "      <Navbar />\n",
    "      <div className=\"tabs-container\">\n",
    "        <Tab label=\"Image Analysis\"><ImageAnalysis /></Tab>\n",
    "        <Tab label=\"Image Insights\"><ImageInsights /></Tab>\n",
    "        {/* other tabs */}\n",
    "      </div>\n",
    "    </AnalysisProvider>\n",
    "  );\n",
    "};\n",
    "```\n",
    "\n",
    "**3. Update ImageAnalysis.jsx:**\n",
    "\n",
    "```jsx\n",
    "import { useContext } from 'react';\n",
    "import { AnalysisContext } from '../contexts/AnalysisContext';\n",
    "\n",
    "const ImageAnalysis = () => {\n",
    "  const { setLastAnalysis } = useContext(AnalysisContext);\n",
    "  \n",
    "  const handleAnalyze = async (file) => {\n",
    "    const response = await fetch('/api/analyze', { /* ... */ });\n",
    "    const results = await response.json();\n",
    "    setLastAnalysis(results); // ← Persist the results\n",
    "    setImages(results.images);\n",
    "  };\n",
    "  \n",
    "  return (\n",
    "    <div>{/* render 9 output images */}</div>\n",
    "  );\n",
    "};\n",
    "```\n",
    "\n",
    "**4. Update ImageInsights.jsx (new component):**\n",
    "\n",
    "```jsx\n",
    "import { useContext, useEffect, useState } from 'react';\n",
    "import { AnalysisContext } from '../contexts/AnalysisContext';\n",
    "\n",
    "const ImageInsights = () => {\n",
    "  const { lastAnalysis } = useContext(AnalysisContext);\n",
    "  const [insights, setInsights] = useState(null);\n",
    "  \n",
    "  useEffect(() => {\n",
    "    if (lastAnalysis) {\n",
    "      // Fetch insights from backend\n",
    "      fetch('/api/analytics/last_image')\n",
    "        .then(r => r.json())\n",
    "        .then(data => setInsights(data));\n",
    "    }\n",
    "  }, [lastAnalysis]);\n",
    "  \n",
    "  if (!lastAnalysis || !insights) {\n",
    "    return <div>No image analyzed yet. Analyze an image first.</div>;\n",
    "  }\n",
    "  \n",
    "  return (\n",
    "    <div>\n",
    "      <h2>Image Insights</h2>\n",
    "      <div className=\"health-card\">\n",
    "        <h3>Health Score: {insights.health_score}/100</h3>\n",
    "        <p>Risk Level: {insights.risk_level}</p>\n",
    "      </div>\n",
    "      {/* Render radar chart, overlap, contribution, insights */}\n",
    "    </div>\n",
    "  );\n",
    "};\n",
    "```\n",
    "\n",
    "### Result:\n",
    "\n",
    "✅ User uploads image in ImageAnalysis  \n",
    "✅ Results saved to context (lastAnalysis)  \n",
    "✅ User switches to ImageInsights → data persists  \n",
    "✅ User switches back to ImageAnalysis → data still there  \n",
    "✅ Can switch tabs infinitely without losing results  \n",
    "\n",
    "### Backend Requirements:\n",
    "\n",
    "```python\n",
    "# /api/analyze - Returns metrics + image URLs\n",
    "@app.route('/api/analyze', methods=['POST'])\n",
    "def analyze_image():\n",
    "    # ... process image ...\n",
    "    return jsonify({\n",
    "        'images': ['url1', 'url2', ...],  # 9 output images\n",
    "        'metrics': {\n",
    "            'crack_risk_score': 0.62,\n",
    "            'vegetation_risk_score': 0.35,\n",
    "            # ... etc\n",
    "        }\n",
    "    })\n",
    "\n",
    "# /api/analytics/last_image - Returns detailed insights\n",
    "@app.route('/api/analytics/last_image')\n",
    "def get_last_image_insights():\n",
    "    # Load last_analysis.json\n",
    "    # Use ImageInsightsAnalyzer to compute insights\n",
    "    return jsonify(insights)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
